{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Seminararbeit**\n",
    "von Leon Lantz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ðŸš€ Bibliotheken-Import und CUDA-VerfÃ¼gbarkeit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from diffusers import DiffusionPipeline\n",
    "from diffusers import StableDiffusion3Pipeline\n",
    "import shutil\n",
    "import json\n",
    "import mediapipe as mp\n",
    "from torch import autocast\n",
    "import random\n",
    "import cv2\n",
    "import string\n",
    "\n",
    "print(\"Cuda verfÃ¼gbar? -->\", torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ðŸ–¼ï¸ COCO Dataset** \n",
    "https://cocodataset.org/\n",
    "\n",
    "- mehr als 200.000 reale Bilder aus unterschiedlichsten Szenarien\n",
    "- unterteilt in 80 Kategorien (Personen, Fahrzeuge, Tiere, ...)\n",
    "- jedes Bild detailliert annotiert, unter anderem mit Bildunterschriften (Captions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordner-Pfade\n",
    "results_path  = 'results/'\n",
    "images_path = 'coco_dataset/train2017'\n",
    "annotations_path = 'coco_dataset/annotations/instances_train2017.json'\n",
    "captions_path = 'coco_dataset/annotations/captions_train2017.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lade die COCO-Annotationen\n",
    "with open(annotations_path, 'r') as f:\n",
    "    coco_annotations = json.load(f)\n",
    "\n",
    "# Lade die COCO-Captions\n",
    "with open(captions_path, 'r') as f:\n",
    "    coco_captions = json.load(f)\n",
    "\n",
    "\n",
    "# Erstelle ein Mapping fÃ¼r ID und Bild-Pfad\n",
    "mapping_filename = {}\n",
    "for image in coco_annotations['images']:\n",
    "    mapping_filename[image['id']] = image['file_name']\n",
    "\n",
    "def get_filename_from_image_id(image_id):\n",
    "    return mapping_filename.get(image_id, \"Bild-ID nicht gefunden\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ðŸš« Nur Bilder mit passenden Captions herauszufiltern**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_word(sentence, word_list):\n",
    "    # Aufteilen des Satzes in WÃ¶rter und Konvertierung in Kleinbuchstaben fÃ¼r den Fallvergleich\n",
    "    words_in_sentence = sentence.lower().split()\n",
    "    # ÃœberprÃ¼fen, ob eines der WÃ¶rter in der Wortliste im Satz enthalten ist\n",
    "    return any(word.lower() in words_in_sentence for word in word_list)\n",
    "\n",
    "def remove_punctuation(sentence):\n",
    "    # Erstelle ein Ãœbersetzungstabelle, die Satzzeichen durch leere Zeichen ersetzt\n",
    "    translation_table = str.maketrans(\"\", \"\", string.punctuation)\n",
    "    # Entferne Satzzeichen aus dem Satz\n",
    "    cleaned_sentence = sentence.translate(translation_table)\n",
    "    return cleaned_sentence\n",
    "\n",
    "# Filter nach captions mit bestimmten Worten\n",
    "words_of_interest = ['person', 'man', 'woman', 'men', 'women', 'kid', 'child', 'face', 'girl', 'boy']\n",
    "words_of_no_interest = ['ski', 'snow']\n",
    "\n",
    "# Filtere Bild-IDs basierend auf Bildunterschriften und fÃ¼lle ein Dictionary\n",
    "image_dict = {}\n",
    "for ann in coco_captions[\"annotations\"]:\n",
    "    caption = remove_punctuation(ann[\"caption\"])\n",
    "    image_id = ann[\"image_id\"]\n",
    "    # ÃœberprÃ¼fe, ob die Bildunterschrift WÃ¶rter von Interesse enthÃ¤lt und keine unerwÃ¼nschten WÃ¶rter enthÃ¤lt\n",
    "    if contains_word(caption, words_of_interest) and not contains_word(caption, words_of_no_interest):\n",
    "        image_dict[image_id] = (caption, get_filename_from_image_id(image_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ðŸ™‚ Gesichtserkennung**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectFace(img_name):\n",
    "    mp_face_detection = mp.solutions.face_detection\n",
    "\n",
    "    def get_rectangle(objDictionary, ss):\n",
    "        left = int(objDictionary.xmin * ss[1])\n",
    "        top = int(objDictionary.ymin * ss[0])\n",
    "        right = int(left + objDictionary.width * ss[1])\n",
    "        bottom = int(top + objDictionary.height * ss[0])\n",
    "        return ((left, top), (right, bottom))\n",
    "\n",
    "    with mp_face_detection.FaceDetection(model_selection=3, min_detection_confidence=0.8) as face_detection:\n",
    "        image = cv2.imread(img_name)\n",
    "        results = face_detection.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    if not results.detections:\n",
    "        return None\n",
    "\n",
    "    faces = []\n",
    "\n",
    "    for obj in results.detections:\n",
    "        ff = get_rectangle(obj.location_data.relative_bounding_box, image.shape)\n",
    "        (left, top), (right, bottom) = ff\n",
    "        faces.append(image[top:bottom, left:right])\n",
    "\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_detected_faces(folder_name):\n",
    "  files = os.listdir(folder_name)\n",
    "\n",
    "  r_count = 0\n",
    "  for f_name in files:\n",
    "    faces = detectFace(os.path.join(folder_name,f_name))\n",
    "    if not faces: \n",
    "      os.remove(os.path.join(folder_name,f_name))\n",
    "      r_count += 1\n",
    "  \n",
    "  return r_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **âœ‚ï¸ Extrahieren von realen Gesichtern**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_faces(img_path, save_path, num_faces_wanted, face_res = 250):\n",
    "\n",
    "  if os.path.exists(save_path):\n",
    "    shutil.rmtree(save_path)\n",
    "  os.mkdir(save_path)\n",
    "\n",
    "  count = 0\n",
    "\n",
    "  for img_id in random.sample(image_dict.keys(), num_faces_wanted*10):\n",
    "\n",
    "    if count >= num_faces_wanted: break\n",
    "\n",
    "    f_name = image_dict.get(img_id)[1]\n",
    "\n",
    "    faces = detectFace(os.path.join(img_path,f_name))\n",
    "    if not faces: continue\n",
    "\n",
    "    for face in faces:\n",
    "      if not face.size: continue\n",
    "      face = cv2.resize(face,(face_res,face_res))\n",
    "      cv2.imwrite(os.path.join((f'{save_path}'), str(count)+'.jpeg'), face)\n",
    "      count += 1      \n",
    "\n",
    "  return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs = 2\n",
    "num_faces_wanted = 1000\n",
    "face_res = 250\n",
    "\n",
    "for n in range(num_runs):\n",
    "    faces_generated = find_faces(images_path, f'{results_path}/realFaces{n}', num_faces_wanted, face_res) # type: ignore\n",
    "    print(f'{faces_generated} Gesichter wurden im Ordner realFaces{n} generiert.')\n",
    "    x = prune_detected_faces((f'{results_path}/realFaces{n}')) # type: ignore\n",
    "    print(f'{x} Gesichter wurden entfernt.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ðŸ”„ Generierung mit Stable Diffusion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_name = \"\"\n",
    "access_token = \"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\"\n",
    "def select_model_pipeline(name):\n",
    "    if name == \"sd14\":\n",
    "        # Instanziiere eine Stable Diffusion Pipeline aus dem Modell \"CompVis/stable-diffusion-v1-4\"\n",
    "        pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", revision=\"fp16\", torch_dtype=torch.float16)  \n",
    "        pipe.to(\"cuda\")\n",
    "    elif name == \"sdxl\":\n",
    "        # Instanziiere eine Stable Diffusion Pipeline aus dem Modell \"CompVis/stable-diffusion-xl-base-1.0\"\n",
    "        pipe = DiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype=torch.float16, use_safetensors=True, variant=\"fp16\")\n",
    "        pipe.to(\"cuda\")\n",
    "    elif name == \"sd11\":\n",
    "        # Instanziiere eine Stable Diffusion Pipeline aus dem Modell \"CompVis/stable-diffusion-xl-base-1.0\"\n",
    "        pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-1\", variant=\"fp16\", torch_dtype=torch.float16)\n",
    "        pipe.to(\"cuda\")\n",
    "    \n",
    "    return pipe, name  # RÃ¼ckgabe der Pipeline am Ende der Funktion\n",
    "    \n",
    "pipe, model_name = select_model_pipeline(\"sd11\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_faces_generated(save_path_images, save_path_faces, num_faces_wanted, face_res=250):\n",
    "\n",
    "  if not os.path.exists(save_path_images):\n",
    "    os.mkdir(save_path_images)    \n",
    "\n",
    "  if not os.path.exists(save_path_faces):\n",
    "    os.mkdir(save_path_faces)    \n",
    "  \n",
    "  count_f = 0\n",
    "  count_i = 0\n",
    "\n",
    "  for img_id in random.sample(image_dict.keys(), num_faces_wanted*10):\n",
    "\n",
    "    if count_f >= num_faces_wanted: break\n",
    "\n",
    "    caption = image_dict.get(img_id)[0]\n",
    "    prompt = caption.lower() + \", photography, colorized, face clarity\"\n",
    "    negative_prompt = \"bad anatomy, low quality, ugly, cartoon, anime, bad limbs, bad face, deformed, blurry eyes, multiple fingers, distorted, unrealistic, poorly rendered, unnatural, messy, pixelated, glitch, out of proportion, extra limbs, artifact, strange eyes, poorly drawn, bad perspective, awkward pose, extra legs, low resolution, bad expression, odd lighting, wrong shadows, blurry background, disconnected body parts, unnatural colors\"\n",
    "\n",
    "    print(prompt)\n",
    "\n",
    "    # generate image\n",
    "    image = pipe(prompt= prompt, negative_prompt=negative_prompt).images[0] \n",
    "    image.save(f'{save_path_images}/{count_i}.jpeg')\n",
    "    count_i += 1\n",
    "\n",
    "    faces = detectFace(os.path.join(f'{save_path_images}/', str(count_i-1)+'.jpeg'))\n",
    "    if not faces: continue\n",
    "\n",
    "    for face in faces:\n",
    "      if not face.size: continue\n",
    "      face = cv2.resize(face,(face_res,face_res))\n",
    "      cv2.imwrite(os.path.join(f'{save_path_faces}/', str(count_f)+'.jpeg'), face)\n",
    "      count_f += 1     \n",
    "\n",
    "  return count_i, count_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs = 1\n",
    "processed_images = set()\n",
    "num_faces_wanted = 900\n",
    "face_res = 250\n",
    "\n",
    "for n in range(num_runs):\n",
    "  images_generated, faces_generated = find_faces_generated(f'{results_path}/imagesGenerated_{model_name}_{n}', f'{results_path}/facesGenerated_{model_name}_{n}', num_faces_wanted, face_res)\n",
    "  print(f'{images_generated} images were generated in folder {results_path}/imagesGenerated_{model_name}_{n}')\n",
    "  print(f'{faces_generated} faces were detected! See them in folder {results_path}/facesGenerated_{model_name}_{n}')\n",
    "  x = prune_detected_faces((f'{results_path}/facesGenerated_{model_name}_{n}'))\n",
    "  print(f'{x} faces were removed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ðŸ”§ Troubleshooting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LÃ¶sche den GPU-Cache\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_images_in_folder(folder_path, new_name):\n",
    "    # List all files in the folder\n",
    "    files = os.listdir(folder_path)\n",
    "    count = 0\n",
    "\n",
    "    for filename in files:\n",
    "        # Construct old file path\n",
    "        old_file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        # Check if it's a file\n",
    "        if os.path.isfile(old_file_path):\n",
    "            #print(filename)\n",
    "            # Get file extension\n",
    "            file_extension = os.path.splitext(filename)[1]\n",
    "            if not filename.lower().startswith('k'):\n",
    "                print(filename)\n",
    "\n",
    "                # Construct new file name and path\n",
    "                new_file_name = f\"{new_name}_{count}{file_extension}\"\n",
    "                new_file_path = os.path.join(folder_path, new_file_name)\n",
    "\n",
    "                # Rename the file\n",
    "                os.rename(old_file_path, new_file_path)\n",
    "                print(f\"Renamed: {old_file_path} to {new_file_path}\")\n",
    "\n",
    "                # Increment the counter\n",
    "                count += 1\n",
    "# Example usage\n",
    "folder_path = \"C:/Users/leonl/Seminararbeit/results/imagesGenerated_sdxl_0\"\n",
    "new_name = \"val\"\n",
    "rename_images_in_folder(folder_path, new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_res = 250\n",
    "faces = detectFace(os.path.join(f'C:/Users/leonl/Seminararbeit/results/valid__83.jpeg'))\n",
    "print(faces)\n",
    "\n",
    "for face in faces:\n",
    "    face = cv2.resize(face,(face_res,face_res))\n",
    "    cv2.imwrite(os.path.join(f'C:/Users/leonl/Seminararbeit/results/test.jpeg'), face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "def resize_images_in_folder(folder_path, output_folder, size=(100, 100)):\n",
    "    # Create output folder if it does not exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Iterate over all files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Check if the file is an image\n",
    "        try:\n",
    "            # Read the image\n",
    "            img = cv2.imread(img_path)\n",
    "            \n",
    "            # Check if image is loaded successfully\n",
    "            if img is not None:\n",
    "                # Resize image\n",
    "                resized_img = cv2.resize(img, size)\n",
    "                \n",
    "                # Save resized image to output folder\n",
    "                output_path = os.path.join(output_folder, filename)\n",
    "                cv2.imwrite(output_path, resized_img)\n",
    "                print(f\"Resized and saved {filename} to {output_folder}\")\n",
    "            else:\n",
    "                print(f\"Skipping file {filename}, as it is not a valid image\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {filename}: {e}\")\n",
    "\n",
    "# Example usage\n",
    "input_folder = 'C:/Users/leonl/Seminararbeit/results/realFaces1'\n",
    "output_folder = 'C:/Users/leonl/Seminararbeit/results/realFaces1SMALL'\n",
    "resize_images_in_folder(input_folder, output_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stable_diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
