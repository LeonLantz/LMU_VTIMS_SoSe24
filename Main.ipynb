{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Seminararbeit**\n",
    "von Leon Lantz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ðŸš€ Bibliotheken-Import und CUDA-VerfÃ¼gbarkeit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leonl\\anaconda3\\envs\\stable_diffusion\\lib\\site-packages\\diffusers\\models\\transformers\\transformer_2d.py:34: FutureWarning: `Transformer2DModelOutput` is deprecated and will be removed in version 1.0.0. Importing `Transformer2DModelOutput` from `diffusers.models.transformer_2d` is deprecated and this will be removed in a future version. Please use `from diffusers.models.modeling_outputs import Transformer2DModelOutput`, instead.\n",
      "  deprecate(\"Transformer2DModelOutput\", \"1.0.0\", deprecation_message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda verfÃ¼gbar? --> True\n",
      "NVIDIA GeForce RTX 4070 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from diffusers import DiffusionPipeline\n",
    "import shutil\n",
    "import json\n",
    "import mediapipe as mp\n",
    "from torch import autocast\n",
    "import random\n",
    "import cv2\n",
    "import string\n",
    "\n",
    "print(\"Cuda verfÃ¼gbar? -->\", torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ðŸ–¼ï¸ COCO Dataset** \n",
    "https://cocodataset.org/\n",
    "\n",
    "- mehr als 200.000 reale Bilder aus unterschiedlichsten Szenarien\n",
    "- unterteilt in 80 Kategorien (Personen, Fahrzeuge, Tiere, ...)\n",
    "- jedes Bild detailliert annotiert, unter anderem mit Bildunterschriften (Captions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordner-Pfade\n",
    "results_path  = 'results/'\n",
    "images_path = 'coco_dataset/train2017'\n",
    "annotations_path = 'coco_dataset/annotations/instances_train2017.json'\n",
    "captions_path = 'coco_dataset/annotations/captions_train2017.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lade die COCO-Annotationen\n",
    "with open(annotations_path, 'r') as f:\n",
    "    coco_annotations = json.load(f)\n",
    "\n",
    "# Lade die COCO-Annotationen\n",
    "with open(captions_path, 'r') as f:\n",
    "    coco_captions = json.load(f)\n",
    "\n",
    "\n",
    "# Erstelle ein Mapping fÃ¼r ID und Bild-Pfad\n",
    "mapping_filename = {}\n",
    "for image in coco_annotations['images']:\n",
    "    mapping_filename[image['id']] = image['file_name']\n",
    "\n",
    "def get_filename_from_image_id(image_id):\n",
    "    return mapping_filename.get(image_id, \"Bild-ID nicht gefunden\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ðŸš« Nur Bilder mit passenden Captions herauszufiltern**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_word(sentence, word_list):\n",
    "    # Aufteilen des Satzes in WÃ¶rter und Konvertierung in Kleinbuchstaben fÃ¼r den Fallvergleich\n",
    "    words_in_sentence = sentence.lower().split()\n",
    "    # ÃœberprÃ¼fen, ob eines der WÃ¶rter in der Wortliste im Satz enthalten ist\n",
    "    return any(word.lower() in words_in_sentence for word in word_list)\n",
    "\n",
    "def remove_punctuation(sentence):\n",
    "    # Erstelle ein Ãœbersetzungstabelle, die Satzzeichen durch leere Zeichen ersetzt\n",
    "    translation_table = str.maketrans(\"\", \"\", string.punctuation)\n",
    "    # Entferne Satzzeichen aus dem Satz\n",
    "    cleaned_sentence = sentence.translate(translation_table)\n",
    "    return cleaned_sentence\n",
    "\n",
    "# Filter nach captions mit bestimmten Worten\n",
    "words_of_interest = ['person', 'man', 'woman', 'men', 'women', 'kid', 'child', 'face', 'girl', 'boy']\n",
    "words_of_no_interest = ['ski', 'snow']\n",
    "\n",
    "# Filtere Bild-IDs basierend auf Bildunterschriften und fÃ¼lle ein Dictionary\n",
    "image_dict = {}\n",
    "for ann in coco_captions[\"annotations\"]:\n",
    "    caption = remove_punctuation(ann[\"caption\"])\n",
    "    image_id = ann[\"image_id\"]\n",
    "    # ÃœberprÃ¼fe, ob die Bildunterschrift WÃ¶rter von Interesse enthÃ¤lt und keine unerwÃ¼nschten WÃ¶rter enthÃ¤lt\n",
    "    if contains_word(caption, words_of_interest) and not contains_word(caption, words_of_no_interest):\n",
    "        image_dict[image_id] = (caption, get_filename_from_image_id(image_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ðŸ™‚ Gesichtserkennung**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectFace(img_name):\n",
    "    mp_face_detection = mp.solutions.face_detection\n",
    "\n",
    "    def get_rectangle(objDictionary, ss):\n",
    "        left = int(objDictionary.xmin * ss[1])\n",
    "        top = int(objDictionary.ymin * ss[0])\n",
    "        right = int(left + objDictionary.width * ss[1])\n",
    "        bottom = int(top + objDictionary.height * ss[0])\n",
    "        return ((left, top), (right, bottom))\n",
    "\n",
    "    with mp_face_detection.FaceDetection(model_selection=3, min_detection_confidence=0.8) as face_detection:\n",
    "        image = cv2.imread(img_name)\n",
    "        results = face_detection.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    if not results.detections:\n",
    "        return None\n",
    "\n",
    "    faces = []\n",
    "\n",
    "    for obj in results.detections:\n",
    "        ff = get_rectangle(obj.location_data.relative_bounding_box, image.shape)\n",
    "        (left, top), (right, bottom) = ff\n",
    "        faces.append(image[top:bottom, left:right])\n",
    "\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_detected_faces(folder_name):\n",
    "  files = os.listdir(folder_name)\n",
    "\n",
    "  r_count = 0\n",
    "  for f_name in files:\n",
    "    faces = detectFace(os.path.join(folder_name,f_name))\n",
    "    if not faces: \n",
    "      os.remove(os.path.join(folder_name,f_name))\n",
    "      r_count += 1\n",
    "  \n",
    "  return r_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **âœ‚ï¸ Extrahieren von realen Gesichtern**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_faces(img_path, save_path, num_faces_wanted, face_res = 100):\n",
    "\n",
    "  if os.path.exists(save_path):\n",
    "    shutil.rmtree(save_path)\n",
    "  os.mkdir(save_path)\n",
    "\n",
    "  count = 0\n",
    "\n",
    "  for img_id in random.sample(image_dict.keys(), num_faces_wanted*10):\n",
    "\n",
    "    if count >= num_faces_wanted: break\n",
    "\n",
    "    f_name = image_dict.get(img_id)[1]\n",
    "\n",
    "    faces = detectFace(os.path.join(img_path,f_name))\n",
    "    if not faces: continue\n",
    "\n",
    "    for face in faces:\n",
    "      if not face.size: continue\n",
    "      face = cv2.resize(face,(face_res,face_res))\n",
    "      cv2.imwrite(os.path.join((f'{save_path}'), str(count)+'.jpeg'), face)\n",
    "      count += 1      \n",
    "\n",
    "  return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leonl\\AppData\\Local\\Temp\\ipykernel_12436\\1246400209.py:9: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  for img_id in random.sample(image_dict.keys(), num_faces_wanted*10):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 Gesichter wurden im Ordner realFaces0 generiert.\n",
      "161 Gesichter wurden entfernt.\n",
      "1000 Gesichter wurden im Ordner realFaces1 generiert.\n",
      "188 Gesichter wurden entfernt.\n"
     ]
    }
   ],
   "source": [
    "num_runs = 2\n",
    "num_faces_wanted = 1000\n",
    "face_res = 100\n",
    "\n",
    "for n in range(num_runs):\n",
    "    faces_generated = find_faces(images_path, f'{results_path}/realFaces{n}', num_faces_wanted, face_res) # type: ignore\n",
    "    print(f'{faces_generated} Gesichter wurden im Ordner realFaces{n} generiert.')\n",
    "    x = prune_detected_faces((f'{results_path}/realFaces{n}')) # type: ignore\n",
    "    print(f'{x} Gesichter wurden entfernt.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ðŸ”„ Generierung mit Stable Diffusion v1-4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leonl\\anaconda3\\envs\\stable_diffusion\\lib\\site-packages\\diffusers\\pipelines\\pipeline_loading_utils.py:219: FutureWarning: You are loading the variant fp16 from CompVis/stable-diffusion-v1-4 via `revision='fp16'` even though you can load it via `variant=`fp16`. Loading model variants via `revision='fp16'` is deprecated and will be removed in diffusers v1. Please use `variant='fp16'` instead.\n",
      "  warnings.warn(\n",
      "text_encoder\\model.safetensors not found\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97da15810a4846d38de58e76f39fa463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leonl\\anaconda3\\envs\\stable_diffusion\\lib\\site-packages\\transformers\\models\\clip\\feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name = \"\"\n",
    "def select_model_pipeline(name):\n",
    "    if name == \"sd14\":\n",
    "        # Instanziiere eine Stable Diffusion Pipeline aus dem Modell \"CompVis/stable-diffusion-v1-4\"\n",
    "        pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", revision=\"fp16\", torch_dtype=torch.float16)  \n",
    "        pipe.to(\"cuda\")\n",
    "    elif name == \"sdxl\":\n",
    "        # Instanziiere eine Stable Diffusion Pipeline aus dem Modell \"CompVis/stable-diffusion-xl-base-1.0\"\n",
    "        pipe = DiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype=torch.float16, use_safetensors=True, variant=\"fp16\")\n",
    "        pipe.to(\"cuda\")\n",
    "    \n",
    "    return pipe, name  # RÃ¼ckgabe der Pipeline am Ende der Funktion\n",
    "    \n",
    "pipe, model_name = select_model_pipeline(\"sd14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_faces_generated(save_path_images, save_path_faces, num_faces_wanted, face_res=100):\n",
    "\n",
    "  if os.path.exists(save_path_images):\n",
    "    shutil.rmtree(save_path_images)    \n",
    "  os.mkdir(save_path_images)\n",
    "\n",
    "  if os.path.exists(save_path_faces):\n",
    "    shutil.rmtree(save_path_faces)    \n",
    "  os.mkdir(save_path_faces)\n",
    "\n",
    "  count_f = 0\n",
    "  count_i = 0\n",
    "\n",
    "  for img_id in random.sample(image_dict.keys(), num_faces_wanted*10):\n",
    "\n",
    "    if count_f >= num_faces_wanted: break\n",
    "\n",
    "    caption = image_dict.get(img_id)[0]\n",
    "    prompt = caption.lower() + \", photography, colorized, face clarity\"\n",
    "    negative_prompt = \"bad anatomy, low quality, ugly, cartoon, anime, bad limbs, bad face, deformed, blurry eyes, multiple fingers, distorted, unrealistic, poorly rendered, unnatural, messy, pixelated, glitch, out of proportion, extra limbs, artifact, strange eyes, poorly drawn, bad perspective, awkward pose, extra legs, low resolution, bad expression, odd lighting, wrong shadows, blurry background, disconnected body parts, unnatural colors\"\n",
    "\n",
    "    print(prompt)\n",
    "\n",
    "    # generate image\n",
    "    image = pipe(prompt= prompt, negative_prompt=negative_prompt).images[0] \n",
    "    image.save(f'{save_path_images}/{count_i}.jpeg')\n",
    "    count_i += 1\n",
    "\n",
    "    faces = detectFace(os.path.join(f'{save_path_images}/', str(count_i-1)+'.jpeg'))\n",
    "    if not faces: continue\n",
    "\n",
    "    for face in faces:\n",
    "      if not face.size: continue\n",
    "      face = cv2.resize(face,(face_res,face_res))\n",
    "      cv2.imwrite(os.path.join(f'{save_path_faces}/', str(count_f)+'.jpeg'), face)\n",
    "      count_f += 1     \n",
    "\n",
    "  return count_i, count_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leonl\\AppData\\Local\\Temp\\ipykernel_12436\\4053283525.py:14: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  for img_id in random.sample(image_dict.keys(), num_faces_wanted*10):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a small child posing for a picture with a stuffed teddy bear, photography, colorized, face clarity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71c97b97785b4adbb6e2150ced1a0421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a dusk view of the city center focused on the statue of a man on a horse , photography, colorized, face clarity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d574c72999994d3ca0bfc69223bc4aae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a person and a dog jumping at a frisbee, photography, colorized, face clarity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9660b5a5459c4b689ab7cec6582cdfb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two young  men playing frisbee in the park, photography, colorized, face clarity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "481f6f0ff1d94f3798551d5a6480bd65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a man is skateboarding while another man watches , photography, colorized, face clarity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90bb84c6cc8b44eca6a0fc5b3ded91fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a crowd of women standing on a sidewalk next to a street, photography, colorized, face clarity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c31db1b4088742e3aa597ea02608d54f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two men are riding dusty brown elephants in dirt, photography, colorized, face clarity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dd3fa028d7a413f836b1b35d7f9c003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a black brown and white dog with a person behind it, photography, colorized, face clarity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c69307e3ed5478b8082545de2856bc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two men discussing and working with electronic equipment, photography, colorized, face clarity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e33207d582b4d74b6924cac066271be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the man is waiting in the bus and he looks sleep, photography, colorized, face clarity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e4f5da310c74c1f89606fca65f114e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a man biting into a slice of pizza while seated at a dining table, photography, colorized, face clarity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12a90c991df844b1a4a03ee3e2908244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a person in a wetsuit being pulled through the water on a board, photography, colorized, face clarity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53f399a08f964e61945b625abcb77fb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a man that is jumping a snowboard on a hill, photography, colorized, face clarity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "791eab5c91c24646b514eac2ab0dec75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chocolate cupcake with a monsters face frosted on top, photography, colorized, face clarity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "210903a616a940c59490db88909b6563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a street with a red and white bus a person on a bicycle and a person riding a motor bike on the street, photography, colorized, face clarity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f5b528692f64c028135140b4a37243a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a girl running to hit a tennis ball with her racquet, photography, colorized, face clarity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffad495f57154828b8f317123b0e5a1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a girl surfing the waves on the ocean, photography, colorized, face clarity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9b9857817884923b68793cddb5e159e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the vintage photo shows a number of men standing near a biplane, photography, colorized, face clarity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41f1e48c848347968ffafabf119beea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two parrots sit on different high branches and face each other, photography, colorized, face clarity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2ca8d26ddf245e09bc00e11d89ee64b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a man kneeling down on a baseball field pitching a baseball, photography, colorized, face clarity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "077d6d5c8f0f4107ac903bd08817cd40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a person is jet skiing on the water with an umbrella , photography, colorized, face clarity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7efbf30b1c6544e08528d7979bb264a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a young boy is smiling and holding a baseball bat, photography, colorized, face clarity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edafb6765c6c42c9b80cdb03cd1b8f5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "young woman with black hair talking on a cellphone while sitting outdoors, photography, colorized, face clarity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fec2c166f35c45f9b7af40c85d4dc4bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a man jumping to catch a ball in front of a goal, photography, colorized, face clarity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d0a2a5347c84c638deebcdae40569e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a man on a motor bike on a road, photography, colorized, face clarity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "469d668c6426419c92fcf126483a7c3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a young man is swinging at a tennis ball, photography, colorized, face clarity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94fb84fdbf5240febd39c73449f25d85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "little girl throwing a frisbee to another child on a field , photography, colorized, face clarity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19e2c20fc6984094a578e61d48da0d44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the man is cutting into a large cake as others sit around the table, photography, colorized, face clarity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1e528f3157b4147805deeda97f24d11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a man standing on one leg on a baseball mound, photography, colorized, face clarity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fee3e2d82014935868a34f0dceafb06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a man on a tennis court with a racquet, photography, colorized, face clarity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33b1b7d90d2e4126aef411ccb63a100b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two young men in a grassy area spinning a frisbee, photography, colorized, face clarity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c86cdb2dc107493c891b271c378e5e13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a woman and a man smiling for a picture, photography, colorized, face clarity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1de7fde4223344db804cfa4967f6b097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_runs = 1\n",
    "processed_images = set()\n",
    "num_faces_wanted = 900\n",
    "face_res = 100\n",
    "\n",
    "for n in range(num_runs):\n",
    "  images_generated, faces_generated = find_faces_generated(f'{results_path}/imagesGenerated_{model_name}_{n}', f'{results_path}/facesGenerated_{model_name}_{n}', num_faces_wanted, face_res)\n",
    "  print(f'{images_generated} images were generated in folder {results_path}/imagesGenerated_{model_name}_{n}')\n",
    "  print(f'{faces_generated} faces were detected! See them in folder {results_path}/facesGenerated{n}')\n",
    "  x = prune_detected_faces((f'{results_path}/facesGenerated{n}'))\n",
    "  print(f'{x} faces were removed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ðŸ”§ Troubleshooting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LÃ¶sche den GPU-Cache\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stable_diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
